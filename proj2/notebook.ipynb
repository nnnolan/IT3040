{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, IMG_WIDTH, IMG_HEIGHT, NUM_CATEGORIES):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # loop through category folders\n",
    "    for category in range(NUM_CATEGORIES):\n",
    "        category_dir = os.path.join(data_dir, str(category))\n",
    "        print(f\"Loading images from {category_dir}\") \n",
    "        #loop through and load the images from each folder into the np array\n",
    "        for filename in os.listdir(category_dir):\n",
    "            \n",
    "            if filename.endswith(\".ppm\") or filename.endswith(\".jpg\"):\n",
    "                \n",
    "                # read image, cv2 does a lot of the heavy lifting for us\n",
    "                img_path = os.path.join(category_dir, filename)\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "                \n",
    "                # add image and label to the lists\n",
    "                images.append(img) \n",
    "                labels.append(category)\n",
    "    \n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', '0', '1', '2']\n",
      "Loading images from gtsrb-small/0\n",
      "Loading images from gtsrb-small/1\n",
      "Loading images from gtsrb-small/2\n",
      "images.shape=(840, 30, 30, 3), labels.shape=(840,)\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"gtsrb-small\"\n",
    "IMG_HEIGHT = 30\n",
    "IMG_WIDTH = 30\n",
    "NUM_CATEGORIES = 3\n",
    "\n",
    "print(os.listdir(data_dir))\n",
    "images, labels = load_data(data_dir, IMG_WIDTH, IMG_HEIGHT, NUM_CATEGORIES)\n",
    "print(f\"images.shape={images.shape}, labels.shape={labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(840, 2700)\n"
     ]
    }
   ],
   "source": [
    "# flatten the images\n",
    "reshaped_images = images.reshape(images.shape[0], -1)\n",
    "print(reshaped_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape=(672, 2700), y_train.shape=(672,)\n"
     ]
    }
   ],
   "source": [
    "# split the data into training, cross validation, and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(reshaped_images, labels, test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
